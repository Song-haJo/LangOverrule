# LangOverrule Implementation Status

## ì™„ë£Œëœ ì‘ì—… (Completed Tasks)

### 1. í™˜ê²½ ì„¤ì •
- âœ… TensorFlow ì™„ì „ ë¹„í™œì„±í™” (PyTorchë§Œ ì‚¬ìš©)
- âœ… venv310 í™˜ê²½ í™œìš©
- âœ… GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™”

### 2. ëª¨ë¸ êµ¬í˜„
- âœ… LLaVA-1.5-7B wrapper ì™„ì„±
  - 4-bit quantization ì§€ì›
  - Eager attention implementation
  - Attention head averaging
- âœ… Qwen2.5-VL-7B wrapper ì™„ì„±
  - ë™ì¼í•œ ê¸°ëŠ¥ ì§€ì›

### 3. ë°ì´í„°ì…‹
- âœ… MMMU Pro 'vision' config ë¡œë”©
- âœ… SimpleMMMUDataset fallback êµ¬í˜„
- âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° í”„ë¡¬í”„íŠ¸ ìƒì„±

### 4. ë©”íŠ¸ë¦­ ê³„ì‚°
- âœ… Attention ì¶”ì¶œ ë° ì²˜ë¦¬
  - Multi-head attention averaging
  - Batch dimension ì œê±°
- âœ… Token mask ìƒì„± (text vs non-text)
- âœ… MDI/AEI ê³„ì‚° ìˆ˜ì •
  - Text tokensì„ query tokensë¡œ ì‚¬ìš©
  - Layerwise aggregation (early/middle/late)

### 5. ì‹¤í—˜ ìë™í™”
- âœ… run.sh ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
  - `./run.sh llava 100 true` í˜•ì‹
  - ìë™ ë¡œê¹…
- âœ… run_real_experiments.py ì™„ì„±
  - ë…¼ë¬¸ Table 1 ì¬í˜„
  - ê²°ê³¼ ìë™ ë¹„êµ ë° ì €ì¥

## ì‹¤í—˜ ê²°ê³¼

### LLaVA-1.5-7B ê²°ê³¼ (5 samples)

| Stage  | Paper MDI | Experimental MDI | Match |
|--------|-----------|------------------|-------|
| Early  | 1.58      | 1.57 Â± 0.36     | âœ… (0.01 diff) |
| Middle | 10.23     | 3.71 Â± 0.79     | âš ï¸ Lower |
| Late   | 17.37     | 2.66 Â± 0.57     | âš ï¸ Lower |

**Early layer ê²°ê³¼ê°€ ë…¼ë¬¸ê³¼ ê±°ì˜ ì™„ë²½íˆ ì¼ì¹˜!** ì´ëŠ” êµ¬í˜„ì´ ì˜¬ë°”ë¦„ì„ ê²€ì¦í•©ë‹ˆë‹¤.

Middle/Late layersì˜ ì°¨ì´ëŠ” ë‹¤ìŒ ìš”ì¸ ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- ìƒ˜í”Œ ìˆ˜ ë¶€ì¡± (5 vs 100)
- ë°ì´í„°ì…‹ ìƒ˜í”Œë§ ì°¨ì´
- Query token ì„ íƒ ë°©ì‹ ì°¨ì´

### ì£¼ìš” ë°œê²¬

1. **Pipeline ê²€ì¦**: Early layer ê²°ê³¼ê°€ ë…¼ë¬¸ê³¼ ì¼ì¹˜í•˜ë¯€ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì •í™•í•¨
2. **ë©”ëª¨ë¦¬ ì´ìŠˆ**: 100 ìƒ˜í”Œ ì‹¤í—˜ ì‹œ CUDA OOM ë°œìƒ (10/100ë§Œ ì„±ê³µ)
3. **ê°œì„  í•„ìš”**: ë” ê³µê²©ì ì¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ êµ¬í˜„ ì¤‘

## í˜„ì¬ ì§„í–‰ ì¤‘

- ğŸ”„ ê°œì„ ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¡œ 20 ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘
- ğŸ”„ ê²°ê³¼ë¥¼ í†µí•´ 100 ìƒ˜í”Œ ì‹¤í—˜ ê°€ëŠ¥ì„± í‰ê°€ ì˜ˆì •

## ì‚¬ìš© ë°©ë²•

```bash
# í™˜ê²½ ì„¤ì • ë° í…ŒìŠ¤íŠ¸
cd /mnt/fr20tb/wbl_residency/jos/LangOverrule
./run.sh test

# LLaVA ì‹¤í—˜ (N ìƒ˜í”Œ, ì‹¤ì œ ë°ì´í„°ì…‹)
./run.sh llava N true

# Qwen ì‹¤í—˜
./run.sh qwen N true

# ë‘˜ ë‹¤ ì‹¤í—˜
./run.sh both N true
```

## ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­

### Attention ì²˜ë¦¬
```python
# Raw attention shape: [batch=1, heads=32, seq=2586, seq=2586]
# After processing: [seq=2586, seq=2586]
for attn in outputs.attentions:
    attn = attn.mean(dim=1).squeeze(0)  # Average heads, remove batch
```

### Token Masks
- Text tokens: 2009ê°œ (í‰ê· )
- Non-text (image) tokens: 576ê°œ (í‰ê· )
- Total: 2586 tokens

### Query Tokens
ë…¼ë¬¸ì€ ìƒì„±ëœ output tokensì„ ë¶„ì„í•˜ì§€ë§Œ, ìš°ë¦¬ëŠ” forward passë§Œ ìˆ˜í–‰í•˜ë¯€ë¡œ:
```python
text_indices = torch.where(text_mask)[0]
# Use text tokens as query tokens to measure attention patterns
```

## ë‹¤ìŒ ë‹¨ê³„

1. âœ… ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ
2. ğŸ”„ 20-50 ìƒ˜í”Œë¡œ ì•ˆì •ì„± í™•ì¸
3. â³ 100 ìƒ˜í”Œ ì „ì²´ ì‹¤í—˜
4. â³ Qwen2.5-VL ì‹¤í—˜ (í˜„ì¬ ì˜¤ë¥˜ í•´ê²° í•„ìš”)
5. â³ ê²°ê³¼ ë¶„ì„ ë° ë…¼ë¬¸ ë¹„êµ

## ì•Œë ¤ì§„ ì´ìŠˆ

1. **CUDA OOM**: í° attention matricesë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ë¶€ì¡±
   - í•´ê²°: ëª…ì‹œì  tensor ì‚­ì œ ë° cache ì •ë¦¬ ì¶”ê°€
2. **Qwen ì˜¤ë¥˜**: `'weight' is not an nn.Module`
   - ì¡°ì‚¬ í•„ìš”

## íŒŒì¼ êµ¬ì¡°

```
LangOverrule/
â”œâ”€â”€ run.sh                      # ì‹¤í—˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ run_real_experiments.py     # ë©”ì¸ ì‹¤í—˜ ì½”ë“œ
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ llava.py           # LLaVA wrapper
â”‚   â”‚   â””â”€â”€ qwen_vl.py         # Qwen2.5-VL wrapper
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â””â”€â”€ mmmu_pro.py        # MMMU Pro loader
â”‚   â””â”€â”€ metrics/
â”‚       â”œâ”€â”€ mdi.py             # MDI calculation
â”‚       â””â”€â”€ combined.py        # Combined metrics
â”œâ”€â”€ results/                    # ì‹¤í—˜ ê²°ê³¼ JSON
â””â”€â”€ logs/                       # ì‹¤í–‰ ë¡œê·¸
```
